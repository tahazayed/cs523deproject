package cs523.bitcoinprice.consumer;

import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.hbase.HBaseConfiguration;
import org.apache.hadoop.hbase.client.Result;
import org.apache.hadoop.hbase.io.ImmutableBytesWritable;
import org.apache.hadoop.hbase.mapreduce.TableInputFormat;
import org.apache.hadoop.hbase.util.Bytes;
import org.apache.spark.SparkConf;
import org.apache.spark.api.java.JavaPairRDD;
import org.apache.spark.api.java.JavaRDD;
import org.apache.spark.api.java.JavaSparkContext;
import org.apache.spark.sql.Dataset;
import org.apache.spark.sql.Row;
import org.apache.spark.sql.SparkSession;

public class BitcoinPriceSparkSql {

    private static final String TABLE_NAME = "bitcoin_price";
    private static final String CF_DEFAULT = "price-info";

    static Configuration config;
    static JavaSparkContext jsc;

    public static void main(String[] args) {

        // Set Spark configuration
        SparkConf sconf = new SparkConf().setAppName("BitcoinPriceSparkSQL")
                .setMaster("local[3]");
        sconf.registerKryoClasses(new Class[] { org.apache.hadoop.hbase.io.ImmutableBytesWritable.class });

        // HBase configuration
        config = HBaseConfiguration.create();
        config.set(TableInputFormat.INPUT_TABLE, TABLE_NAME);

        // Initialize Spark context
        jsc = new JavaSparkContext(sconf);
        SparkSession sparkSession = SparkSession.builder()
                .config(sconf)
                .getOrCreate();

        // Read Bitcoin price data from HBase
        JavaPairRDD<ImmutableBytesWritable, Result> hBaseRDD = readTableByJavaPairRDD();
        System.out.println("Number of rows in HBase table: " + hBaseRDD.count());

        // Convert HBase data to BitcoinPrice objects
        JavaRDD<BitcoinPrice> rows = hBaseRDD.map(x -> {
            BitcoinPrice bitcoinPrice = new BitcoinPrice();

            bitcoinPrice.setAssetId(Bytes.toString(x._1.get()));
            bitcoinPrice.setPrice(Bytes.toDouble(x._2.getValue(Bytes.toBytes(CF_DEFAULT), Bytes.toBytes("price"))));
            bitcoinPrice.setTimestamp(Bytes.toString(x._2.getValue(Bytes.toBytes(CF_DEFAULT), Bytes.toBytes("timestamp"))));
            bitcoinPrice.setSize(Bytes.toDouble(x._2.getValue(Bytes.toBytes(CF_DEFAULT), Bytes.toBytes("size"))));

            return bitcoinPrice;
        });

        // Create Dataset for SQL queries
        Dataset<Row> tableData = sparkSession.createDataFrame(rows, BitcoinPrice.class);
        tableData.createOrReplaceTempView(TABLE_NAME);
        tableData.printSchema();

        // Example query: Get the average price of Bitcoin
        Dataset<Row> query1 = sparkSession.sql("SELECT AVG(price) as avg_price FROM bitcoin_price");
        query1.show();

        // Example query: Get the top 10 latest prices
        Dataset<Row> query2 = sparkSession.sql("SELECT * FROM bitcoin_price ORDER BY timestamp DESC LIMIT 10");
        query2.show();

        // Stop the Spark context
        jsc.stop();
    }

    // Method to read Bitcoin price data from HBase
    public static JavaPairRDD<ImmutableBytesWritable, Result> readTableByJavaPairRDD() {
        return jsc.newAPIHadoopRDD(config, TableInputFormat.class,
                org.apache.hadoop.hbase.io.ImmutableBytesWritable.class,
                org.apache.hadoop.hbase.client.Result.class);
    }
}


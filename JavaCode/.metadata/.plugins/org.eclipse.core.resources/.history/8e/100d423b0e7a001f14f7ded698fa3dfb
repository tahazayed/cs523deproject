package cs523.bitcoinprice.consumer;

import com.google.gson.Gson;
import com.google.gson.JsonSyntaxException;
import org.apache.kafka.clients.consumer.ConsumerRecord;
import org.apache.kafka.common.serialization.StringDeserializer;
import org.apache.spark.SparkConf;
import org.apache.spark.api.java.JavaPairRDD;
import org.apache.spark.api.java.function.VoidFunction;
import org.apache.spark.streaming.Durations;
import org.apache.spark.streaming.api.java.JavaDStream;
import org.apache.spark.streaming.api.java.JavaInputDStream;
import org.apache.spark.streaming.api.java.JavaStreamingContext;
import org.apache.spark.streaming.kafka010.ConsumerStrategies;
import org.apache.spark.streaming.kafka010.DirectKafkaInputDStream;
import org.apache.spark.streaming.kafka010.KafkaUtils;
import org.apache.spark.streaming.kafka010.LocationStrategies;

import java.util.*;

public class BitcoinPriceListener {

    public static void main(String[] args) throws Exception {

        // Create Spark Configuration
        SparkConf conf = new SparkConf().setAppName("BitcoinPriceListener").setMaster("local[*]");

        // Create Streaming Context
        JavaStreamingContext streamingContext = new JavaStreamingContext(conf, Durations.seconds(5));

        // Kafka parameters
        Map<String, Object> kafkaParams = new HashMap<>();
        kafkaParams.put("bootstrap.servers", "localhost:9092");
        kafkaParams.put("key.deserializer", StringDeserializer.class);
        kafkaParams.put("value.deserializer", StringDeserializer.class);
        kafkaParams.put("group.id", "bitcoin-price-consumer-group");
        kafkaParams.put("auto.offset.reset", "latest");
        kafkaParams.put("enable.auto.commit", false);

        // Topic to consume
        Collection<String> topics = Arrays.asList("bitcoin-price");

        // Create Kafka Direct Stream
        DirectKafkaInputDStream<String, String> kafkaStream =
                KafkaUtils.createDirectStream(
                        streamingContext,
                        LocationStrategies.PreferConsistent(),
                        ConsumerStrategies.<String, String>Subscribe(topics, kafkaParams)
                );

        // Process each message in the stream
        JavaDStream<String> messages = kafkaStream.map(ConsumerRecord::value);

        // Gson instance for JSON parsing
        Gson gson = new Gson();

        messages.foreachRDD(new VoidFunction<JavaPairRDD<String, String>>() {
            @Override
            public void call(JavaPairRDD<String, String> rdd) {
                rdd.foreach(record -> {
                    String message = record;

                    // Check if the message starts with a JSON object
                    if (message.startsWith("{")) {
                        try {
                            // Assuming you have a class BitcoinPrice to map JSON data
                            BitcoinPrice price = gson.fromJson(message, BitcoinPrice.class);
                            // Do something with the parsed object
                            System.out.println("Parsed Bitcoin Price Object: " + price);
                        } catch (JsonSyntaxException e) {
                            System.err.println("Failed to parse JSON: " + e.getMessage());
                        }
                    } else {
                        // Handle non-JSON messages (e.g., log or ignore)
                        System.out.println("Non-JSON message received: " + message);
                    }
                });
            }
        });

        // Start the streaming context and await termination
        streamingContext.start();
        streamingContext.awaitTermination();
    }
}
